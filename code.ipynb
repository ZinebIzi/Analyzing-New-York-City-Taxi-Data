{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: shapely in /usr/local/lib/python3.9/dist-packages (2.0.6)\n",
      "Requirement already satisfied: numpy<3,>=1.14 in /usr/local/lib/python3.9/dist-packages (from shapely) (2.0.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install shapely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "82psKoK_Ha9k"
   },
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "from pyspark.sql import SparkSession, Window\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import lead, col, avg, when, count, unix_timestamp, lag, sum, round\n",
    "import json\n",
    "from shapely.geometry import Point, Polygon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "gWRNPb6YIEUK"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/04 16:59:39 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Spark session\n",
    "spark = SparkSession.builder.appName(\"TaxiDataAnalysis\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ic_ibdUhIjml",
    "outputId": "f14fcf68-412d-4468-a324-7f00b28f11b4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial DataFrame Schema:\n",
      "root\n",
      " |-- hack_license: string (nullable = true)\n",
      " |-- pickup_datetime: string (nullable = true)\n",
      " |-- dropoff_datetime: string (nullable = true)\n",
      " |-- pickup_longitude: double (nullable = true)\n",
      " |-- pickup_latitude: double (nullable = true)\n",
      " |-- dropoff_longitude: double (nullable = true)\n",
      " |-- dropoff_latitude: double (nullable = true)\n",
      "\n",
      "\n",
      "Sample Data:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+----------------+----------------+---------------+-----------------+----------------+\n",
      "|        hack_license|pickup_datetime|dropoff_datetime|pickup_longitude|pickup_latitude|dropoff_longitude|dropoff_latitude|\n",
      "+--------------------+---------------+----------------+----------------+---------------+-----------------+----------------+\n",
      "|BA96DE419E711691B...| 01-01-13 15:11|  01-01-13 15:18|      -73.978165|      40.757977|       -73.989838|       40.751171|\n",
      "|9FD8F69F0804BDB55...| 06-01-13 00:18|  06-01-13 00:22|      -74.006683|      40.731781|       -73.994499|        40.75066|\n",
      "|9FD8F69F0804BDB55...| 05-01-13 18:49|  05-01-13 18:54|      -74.004707|       40.73777|       -74.009834|       40.726002|\n",
      "|51EE87E3205C985EF...| 07-01-13 23:54|  07-01-13 23:58|      -73.974602|      40.759945|       -73.984734|       40.759388|\n",
      "|51EE87E3205C985EF...| 07-01-13 23:25|  07-01-13 23:34|       -73.97625|      40.748528|       -74.002586|       40.747868|\n",
      "+--------------------+---------------+----------------+----------------+---------------+-----------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read CSV and select required columns\n",
    "df = (spark.read\n",
    "      .option(\"header\", True)\n",
    "      .option(\"inferSchema\", True)\n",
    "      .csv(\"data/Sample NYC Data.csv\")\n",
    "      .select(\n",
    "          \"hack_license\",\n",
    "          \"pickup_datetime\",\n",
    "          \"dropoff_datetime\",\n",
    "          \"pickup_longitude\",\n",
    "          \"pickup_latitude\",\n",
    "          \"dropoff_longitude\",\n",
    "          \"dropoff_latitude\"\n",
    "      ))\n",
    "\n",
    "# Display initial data\n",
    "print(\"Initial DataFrame Schema:\")\n",
    "df.printSchema()\n",
    "print(\"\\nSample Data:\")\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SGQIbBScJE6X"
   },
   "source": [
    "# Data Cleaning and Duration Calculation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9VVne4pGJClN",
    "outputId": "c6475c42-3d5e-43bf-b4d2-b18994e58c67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned DataFrame Schema:\n",
      "root\n",
      " |-- hack_license: string (nullable = true)\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      " |-- dropoff_datetime: timestamp (nullable = true)\n",
      " |-- pickup_longitude: double (nullable = true)\n",
      " |-- pickup_latitude: double (nullable = true)\n",
      " |-- dropoff_longitude: double (nullable = true)\n",
      " |-- dropoff_latitude: double (nullable = true)\n",
      " |-- duration: long (nullable = true)\n",
      "\n",
      "\n",
      "Sample Cleaned Data:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+----------------+---------------+-----------------+----------------+--------+\n",
      "|        hack_license|    pickup_datetime|   dropoff_datetime|pickup_longitude|pickup_latitude|dropoff_longitude|dropoff_latitude|duration|\n",
      "+--------------------+-------------------+-------------------+----------------+---------------+-----------------+----------------+--------+\n",
      "|BA96DE419E711691B...|2013-01-01 15:11:00|2013-01-01 15:18:00|      -73.978165|      40.757977|       -73.989838|       40.751171|     420|\n",
      "|9FD8F69F0804BDB55...|2013-01-06 00:18:00|2013-01-06 00:22:00|      -74.006683|      40.731781|       -73.994499|        40.75066|     240|\n",
      "|9FD8F69F0804BDB55...|2013-01-05 18:49:00|2013-01-05 18:54:00|      -74.004707|       40.73777|       -74.009834|       40.726002|     300|\n",
      "|51EE87E3205C985EF...|2013-01-07 23:54:00|2013-01-07 23:58:00|      -73.974602|      40.759945|       -73.984734|       40.759388|     240|\n",
      "|51EE87E3205C985EF...|2013-01-07 23:25:00|2013-01-07 23:34:00|       -73.97625|      40.748528|       -74.002586|       40.747868|     540|\n",
      "+--------------------+-------------------+-------------------+----------------+---------------+-----------------+----------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Record count before cleaning: 99999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 7:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Record count after cleaning: 99549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Clean data and add duration column\n",
    "df_cleaned = df \\\n",
    "    .withColumn(\"pickup_datetime\", F.to_timestamp(\"pickup_datetime\", \"dd-MM-yy HH:mm\")) \\\n",
    "    .withColumn(\"dropoff_datetime\", F.to_timestamp(\"dropoff_datetime\", \"dd-MM-yy HH:mm\")) \\\n",
    "    .withColumn(\"duration\",\n",
    "        F.unix_timestamp(\"dropoff_datetime\") - F.unix_timestamp(\"pickup_datetime\")) \\\n",
    "    .filter(\n",
    "        # Remove null values\n",
    "        F.col(\"pickup_datetime\").isNotNull() &\n",
    "        F.col(\"dropoff_datetime\").isNotNull() &\n",
    "        F.col(\"pickup_longitude\").isNotNull() &\n",
    "        F.col(\"pickup_latitude\").isNotNull() &\n",
    "        F.col(\"dropoff_longitude\").isNotNull() &\n",
    "        F.col(\"dropoff_latitude\").isNotNull() &\n",
    "        # Remove invalid times (negative duration or > 4 hours)\n",
    "        (F.col(\"duration\") > 0) &\n",
    "        (F.col(\"duration\") <= 14400)\n",
    "    )\n",
    "\n",
    "# Display cleaned data\n",
    "print(\"Cleaned DataFrame Schema:\")\n",
    "df_cleaned.printSchema()\n",
    "print(\"\\nSample Cleaned Data:\")\n",
    "df_cleaned.show(5)\n",
    "\n",
    "# Display summary statistics\n",
    "print(\"\\nRecord count before cleaning:\", df.count())\n",
    "print(\"Record count after cleaning:\", df_cleaned.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mfsvAOBTJfph"
   },
   "source": [
    "# Borough Boundary Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s3bTrQ9sJQid",
    "outputId": "a4d4c4a0-3206-4fa6-981e-2c91335f8e54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Boroughs: ['Manhattan', 'Bronx', 'Brooklyn', 'Queens', 'Staten Island']\n"
     ]
    }
   ],
   "source": [
    "def load_borough_polygons(geojson_path):\n",
    "    \"\"\"Load and process borough boundaries from GeoJSON file\"\"\"\n",
    "    with open(geojson_path) as f:\n",
    "        gj = json.load(f)\n",
    "\n",
    "    borough_polygons = {}\n",
    "    # Sort features by borough code and polygon size\n",
    "    for feature in sorted(gj['features'],\n",
    "                         key=lambda x: (x['properties']['boroughCode'],\n",
    "                                      -Polygon(x['geometry']['coordinates'][0]).area)):\n",
    "        borough = feature['properties']['borough']\n",
    "        polygon = Polygon(feature['geometry']['coordinates'][0])\n",
    "        # Keep only the first (largest) polygon for each borough\n",
    "        if borough not in borough_polygons:\n",
    "            borough_polygons[borough] = polygon\n",
    "    return borough_polygons\n",
    "\n",
    "# Load borough polygons\n",
    "borough_polygons = load_borough_polygons(\"data/nyc-boroughs.geojson\")\n",
    "broadcast_polygons = spark.sparkContext.broadcast(borough_polygons)\n",
    "\n",
    "print(\"Loaded Boroughs:\", list(borough_polygons.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VobGcpE9J2hg"
   },
   "source": [
    "# Creating Spatial Matching Functions\n",
    "\n",
    "In this section, we implement functions to match geographical coordinates to their corresponding NYC boroughs. We'll create and register a User-Defined Function (UDF) in Spark to enable efficient spatial queries across our dataset.\n",
    "\n",
    "## Steps :\n",
    "1. Create point-in-polygon matching function\n",
    "2. Register the function as a Spark UDF\n",
    "3. Prepare for parallel processing with broadcast variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ojEeJPQWJy53"
   },
   "outputs": [],
   "source": [
    "def get_borough(lon, lat, polygons):\n",
    "    \"\"\"Determine borough for a given coordinate pair\"\"\"\n",
    "    if lon is None or lat is None:\n",
    "        return None\n",
    "    point = Point(lon, lat)\n",
    "    for borough, polygon in polygons.items():\n",
    "        if polygon.contains(point):\n",
    "            return borough\n",
    "    return None\n",
    "\n",
    "# Register UDF\n",
    "borough_udf = F.udf(\n",
    "    lambda lon, lat: get_borough(lon, lat, broadcast_polygons.value),\n",
    "    StringType()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3c3aulkLKloz"
   },
   "source": [
    "# Data Enrichment with Borough Information\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "suLs1duOKhlD",
    "outputId": "5007ba36-cc95-4c0f-a2d0-59426b84ae2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final DataFrame Schema:\n",
      "root\n",
      " |-- hack_license: string (nullable = true)\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      " |-- dropoff_datetime: timestamp (nullable = true)\n",
      " |-- pickup_longitude: double (nullable = true)\n",
      " |-- pickup_latitude: double (nullable = true)\n",
      " |-- dropoff_longitude: double (nullable = true)\n",
      " |-- dropoff_latitude: double (nullable = true)\n",
      " |-- duration: long (nullable = true)\n",
      " |-- pickup_borough: string (nullable = true)\n",
      " |-- dropoff_borough: string (nullable = true)\n",
      "\n",
      "\n",
      "Sample Final Data:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+----------------+---------------+-----------------+----------------+--------+--------------+---------------+\n",
      "|        hack_license|    pickup_datetime|   dropoff_datetime|pickup_longitude|pickup_latitude|dropoff_longitude|dropoff_latitude|duration|pickup_borough|dropoff_borough|\n",
      "+--------------------+-------------------+-------------------+----------------+---------------+-----------------+----------------+--------+--------------+---------------+\n",
      "|BA96DE419E711691B...|2013-01-01 15:11:00|2013-01-01 15:18:00|      -73.978165|      40.757977|       -73.989838|       40.751171|     420|     Manhattan|      Manhattan|\n",
      "|9FD8F69F0804BDB55...|2013-01-06 00:18:00|2013-01-06 00:22:00|      -74.006683|      40.731781|       -73.994499|        40.75066|     240|     Manhattan|      Manhattan|\n",
      "|9FD8F69F0804BDB55...|2013-01-05 18:49:00|2013-01-05 18:54:00|      -74.004707|       40.73777|       -74.009834|       40.726002|     300|     Manhattan|      Manhattan|\n",
      "|51EE87E3205C985EF...|2013-01-07 23:54:00|2013-01-07 23:58:00|      -73.974602|      40.759945|       -73.984734|       40.759388|     240|     Manhattan|      Manhattan|\n",
      "|51EE87E3205C985EF...|2013-01-07 23:25:00|2013-01-07 23:34:00|       -73.97625|      40.748528|       -74.002586|       40.747868|     540|     Manhattan|      Manhattan|\n",
      "+--------------------+-------------------+-------------------+----------------+---------------+-----------------+----------------+--------+--------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      "Trips by Pickup Borough:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n",
      "|pickup_borough|count|\n",
      "+--------------+-----+\n",
      "|        Queens| 5871|\n",
      "|          null| 1681|\n",
      "|      Brooklyn| 1960|\n",
      "| Staten Island|    2|\n",
      "|     Manhattan|89956|\n",
      "|         Bronx|   79|\n",
      "+--------------+-----+\n",
      "\n",
      "\n",
      "Trips by Dropoff Borough:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----+\n",
      "|dropoff_borough|count|\n",
      "+---------------+-----+\n",
      "|         Queens| 5437|\n",
      "|           null| 2107|\n",
      "|       Brooklyn| 3591|\n",
      "|  Staten Island|   13|\n",
      "|      Manhattan|88008|\n",
      "|          Bronx|  393|\n",
      "+---------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add borough information to cleaned dataset\n",
    "df_final = df_cleaned \\\n",
    "    .withColumn(\"pickup_borough\",\n",
    "                borough_udf(F.col(\"pickup_longitude\"), F.col(\"pickup_latitude\"))) \\\n",
    "    .withColumn(\"dropoff_borough\",\n",
    "                borough_udf(F.col(\"dropoff_longitude\"), F.col(\"dropoff_latitude\")))\n",
    "\n",
    "# Cache the final dataframe\n",
    "df_final.cache()\n",
    "\n",
    "# Display results\n",
    "print(\"Final DataFrame Schema:\")\n",
    "df_final.printSchema()\n",
    "print(\"\\nSample Final Data:\")\n",
    "df_final.show(5)\n",
    "print(\"\\nTrips by Pickup Borough:\")\n",
    "df_final.groupBy(\"pickup_borough\").count().show()\n",
    "print(\"\\nTrips by Dropoff Borough:\")\n",
    "df_final.groupBy(\"dropoff_borough\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3aAGyPlqMmBW",
    "outputId": "1c6c4667-af71-4a9d-eb1a-b4b03e092f81"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with 'null' pickup_borough: 1681\n",
      "Number of rows with 'null' dropoff_borough: 2107\n"
     ]
    }
   ],
   "source": [
    "# Count rows where pickup_borough is \"null\"\n",
    "pickup_null_count = df_final.filter(df_final[\"pickup_borough\"].isNull()).count()\n",
    "\n",
    "# Count rows where dropoff_borough is \"null\"\n",
    "dropoff_null_count = df_final.filter(df_final[\"dropoff_borough\"].isNull()).count()\n",
    "\n",
    "print(f\"Number of rows with 'null' pickup_borough: {pickup_null_count}\")\n",
    "print(f\"Number of rows with 'null' dropoff_borough: {dropoff_null_count}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "erlw_W12M1py"
   },
   "outputs": [],
   "source": [
    "df_final = df_final.filter(\n",
    "    (df_final[\"pickup_borough\"].isNotNull()) &\n",
    "    (df_final[\"dropoff_borough\"].isNotNull())\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9irRndXDmVgo"
   },
   "source": [
    "# Query1 : Utilization  - Understanding Taxi Utilization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "JZ0IPp8fmfVa"
   },
   "outputs": [],
   "source": [
    "#  1 --> Create window specification for ordering trips by taxi and pickup time\n",
    "window_spec = Window.partitionBy(\"hack_license\").orderBy(\"pickup_datetime\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "N2Yy2GebmhTH"
   },
   "outputs": [],
   "source": [
    "# 2 --> Calculating idle times\n",
    "df_with_idle = df_final.withColumn(\n",
    "    \"prev_dropoff_ts\",\n",
    "    lag(\"dropoff_datetime\").over(window_spec)\n",
    ").withColumn(\n",
    "    \"idle_time_seconds\",\n",
    "    when(\n",
    "        col(\"prev_dropoff_ts\").isNotNull(),\n",
    "        unix_timestamp(col(\"pickup_datetime\")) - unix_timestamp(col(\"prev_dropoff_ts\"))\n",
    "    ).otherwise(0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "01LCfr9bnNlD"
   },
   "outputs": [],
   "source": [
    "# 3 --> Identify New Sessions and Filter Idle Time\n",
    "df_with_sessions = df_with_idle.withColumn(\n",
    "    \"is_new_session\",\n",
    "    when(col(\"idle_time_seconds\") > 14400, True).otherwise(False)\n",
    ").withColumn(\n",
    "    \"valid_idle_time\",\n",
    "    when(\n",
    "        (col(\"idle_time_seconds\") <= 14400) & (col(\"idle_time_seconds\") > 0),\n",
    "        col(\"idle_time_seconds\")\n",
    "    ).otherwise(0)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "hYCcv9FNnoD1"
   },
   "outputs": [],
   "source": [
    "\n",
    "# 4--> Calculate session numbers\n",
    "df_with_session_nums = df_with_sessions.withColumn(\n",
    "    \"session_id\",\n",
    "    sum(col(\"is_new_session\").cast(\"int\")).over(window_spec)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a9tJu-zkn4gG",
    "outputId": "685eee1d-fd06-40b5-9a13-1fff289695b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing utilization rates...\n"
     ]
    }
   ],
   "source": [
    "# 5--> Calculate utilization metrics\n",
    "print(\"Computing utilization rates...\")\n",
    "utilization = df_with_session_nums.groupBy(\"hack_license\", \"session_id\").agg(\n",
    "    sum(\"duration\").alias(\"total_occupied_time\"),\n",
    "    sum(\"valid_idle_time\").alias(\"total_idle_time\"),\n",
    "    count(\"*\").alias(\"trips_count\")\n",
    ").withColumn(\n",
    "    \"total_time\",\n",
    "    col(\"total_occupied_time\") + col(\"total_idle_time\")\n",
    ").withColumn(\n",
    "    \"utilization_rate\",\n",
    "    round((col(\"total_occupied_time\") / col(\"total_time\") * 100), 2)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "enon1keun5wi",
    "outputId": "88f4de90-085a-467a-ceb3-c97ad211b887"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utilization calculation completed!\n"
     ]
    }
   ],
   "source": [
    "# Cache the results for multiple analyses\n",
    "utilization.cache()\n",
    "\n",
    "print(\"Utilization calculation completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fonoF4man9J4",
    "outputId": "8e5cc3b8-e604-4700-dc14-da6c526453fb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 36:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+-------------------+---------------+-----------+----------+----------------+\n",
      "|        hack_license|session_id|total_occupied_time|total_idle_time|trips_count|total_time|utilization_rate|\n",
      "+--------------------+----------+-------------------+---------------+-----------+----------+----------------+\n",
      "|02856AFC22881ABCA...|         0|               1860|           2640|          3|      4500|           41.33|\n",
      "|03A2D28F831C5C3E5...|         0|               6900|          19020|          8|     25920|           26.62|\n",
      "|069B5562096AF7684...|         0|                600|              0|          1|       600|           100.0|\n",
      "|0FBF11956EE14B253...|         0|               7800|          25560|         10|     33360|           23.38|\n",
      "|130328475AD7427AF...|         0|                720|              0|          1|       720|           100.0|\n",
      "+--------------------+----------+-------------------+---------------+-----------+----------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "utilization.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C2pkgr0MlvnC"
   },
   "source": [
    "## Query 2 : The average time it takes for a taxi to find its next fare(trip) per destination borough. ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "DVQE-0QFNTcA"
   },
   "outputs": [],
   "source": [
    "# Get the pickup timestamp of the next trip for each taxi's row\n",
    "df_final_with_next_pickup_timestamp = df_final.withColumn(\"next_pickup_timestamp\",\n",
    "                                                  lead(\"pickup_datetime\").over(window_spec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "dc4mwqKTNa-y"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+----------------+---------------+-----------------+----------------+--------+--------------+---------------+---------------------+------------+\n",
      "|        hack_license|    pickup_datetime|   dropoff_datetime|pickup_longitude|pickup_latitude|dropoff_longitude|dropoff_latitude|duration|pickup_borough|dropoff_borough|next_pickup_timestamp|waiting_time|\n",
      "+--------------------+-------------------+-------------------+----------------+---------------+-----------------+----------------+--------+--------------+---------------+---------------------+------------+\n",
      "|02856AFC22881ABCA...|2013-01-13 02:42:00|2013-01-13 02:51:00|      -73.956192|      40.772175|       -73.993713|       40.761349|     540|     Manhattan|      Manhattan|  2013-01-13 03:32:00|        2460|\n",
      "|02856AFC22881ABCA...|2013-01-13 03:32:00|2013-01-13 03:41:00|      -74.008347|      40.725906|       -73.993164|       40.722485|     540|     Manhattan|      Manhattan|  2013-01-13 03:44:00|         180|\n",
      "|02856AFC22881ABCA...|2013-01-13 03:44:00|2013-01-13 03:57:00|      -73.989746|      40.729691|       -73.983513|       40.763943|     780|     Manhattan|      Manhattan|                 null|        null|\n",
      "|03A2D28F831C5C3E5...|2013-01-13 07:55:00|2013-01-13 08:00:00|      -73.986137|      40.756985|       -74.000748|       40.761929|     300|     Manhattan|      Manhattan|  2013-01-13 09:33:00|        5580|\n",
      "|03A2D28F831C5C3E5...|2013-01-13 09:33:00|2013-01-13 09:36:00|      -73.982437|      40.761356|       -73.974678|       40.757561|     180|     Manhattan|      Manhattan|  2013-01-13 09:47:00|         660|\n",
      "|03A2D28F831C5C3E5...|2013-01-13 09:47:00|2013-01-13 10:02:00|      -73.985687|      40.762012|       -73.962105|       40.810631|     900|     Manhattan|      Manhattan|  2013-01-13 11:09:00|        4020|\n",
      "|03A2D28F831C5C3E5...|2013-01-13 11:09:00|2013-01-13 11:20:00|        -73.9879|      40.732559|        -74.00946|       40.720123|     660|     Manhattan|      Manhattan|  2013-01-13 11:22:00|         120|\n",
      "|03A2D28F831C5C3E5...|2013-01-13 11:22:00|2013-01-13 11:25:00|       -74.01049|      40.718857|       -74.010315|       40.719521|     180|     Manhattan|      Manhattan|  2013-01-13 11:35:00|         600|\n",
      "|03A2D28F831C5C3E5...|2013-01-13 11:35:00|2013-01-13 12:12:00|      -74.016556|      40.710953|       -73.834946|       40.670841|    2220|     Manhattan|         Queens|  2013-01-13 13:51:00|        5940|\n",
      "|03A2D28F831C5C3E5...|2013-01-13 13:51:00|2013-01-13 14:04:00|      -73.786026|      40.641499|       -73.864487|       40.768295|     780|        Queens|         Queens|  2013-01-13 14:39:00|        2100|\n",
      "|03A2D28F831C5C3E5...|2013-01-13 14:39:00|2013-01-13 15:07:00|      -73.789993|      40.643993|        -73.96492|       40.753227|    1680|        Queens|      Manhattan|                 null|        null|\n",
      "|069B5562096AF7684...|2013-01-13 02:14:00|2013-01-13 02:24:00|      -74.003937|      40.731655|       -73.993919|       40.741348|     600|     Manhattan|      Manhattan|                 null|        null|\n",
      "|0FBF11956EE14B253...|2013-01-13 10:19:00|2013-01-13 10:44:00|      -73.885307|      40.773106|       -73.978302|        40.75885|    1500|        Queens|      Manhattan|  2013-01-13 10:46:00|         120|\n",
      "|0FBF11956EE14B253...|2013-01-13 10:46:00|2013-01-13 10:54:00|      -73.979813|       40.76186|        -73.99839|       40.760872|     480|     Manhattan|      Manhattan|  2013-01-13 12:25:00|        5460|\n",
      "|0FBF11956EE14B253...|2013-01-13 12:25:00|2013-01-13 12:47:00|      -73.977554|      40.761654|       -73.872147|       40.774464|    1320|     Manhattan|         Queens|  2013-01-13 14:19:00|        5520|\n",
      "|0FBF11956EE14B253...|2013-01-13 14:19:00|2013-01-13 14:44:00|      -73.786011|      40.643719|       -73.946671|       40.780605|    1500|        Queens|      Manhattan|  2013-01-13 14:54:00|         600|\n",
      "|0FBF11956EE14B253...|2013-01-13 14:54:00|2013-01-13 15:05:00|      -73.948685|       40.78244|       -73.971275|       40.801121|     660|     Manhattan|      Manhattan|  2013-01-13 17:27:00|        8520|\n",
      "|0FBF11956EE14B253...|2013-01-13 17:27:00|2013-01-13 17:35:00|        -73.9786|      40.761871|       -73.973274|       40.748611|     480|     Manhattan|      Manhattan|  2013-01-13 17:45:00|         600|\n",
      "|0FBF11956EE14B253...|2013-01-13 17:45:00|2013-01-13 17:55:00|      -73.993027|      40.743065|       -73.962509|       40.772202|     600|     Manhattan|      Manhattan|  2013-01-13 18:02:00|         420|\n",
      "|0FBF11956EE14B253...|2013-01-13 18:02:00|2013-01-13 18:09:00|      -73.974632|      40.759487|       -73.988808|       40.751179|     420|     Manhattan|      Manhattan|  2013-01-13 18:21:00|         720|\n",
      "+--------------------+-------------------+-------------------+----------------+---------------+-----------------+----------------+--------+--------------+---------------+---------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compute the time difference in seconds between dropoff and the next pickup\n",
    "df_with_with_waiting_time = df_final_with_next_pickup_timestamp.withColumn(\n",
    "    \"waiting_time\",\n",
    "    F.when(\n",
    "        F.col(\"next_pickup_timestamp\").isNotNull(),\n",
    "        (F.unix_timestamp(\"next_pickup_timestamp\") - F.unix_timestamp(\"dropoff_datetime\"))\n",
    "    ).otherwise(None)\n",
    ")\n",
    "\n",
    "df_with_with_waiting_time.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "RE3GGM24NnL0"
   },
   "outputs": [],
   "source": [
    "# Compute the average waiting time for each taxi in each dropoff borough\n",
    "avg_wait_time_per_taxi_per_borough = (df_with_with_waiting_time.groupBy(\"hack_license\", \"dropoff_borough\")\n",
    "                                .agg(avg(\"waiting_time\").alias(\"avg_waiting_time_seconds\"))\n",
    "                                .orderBy(\"hack_license\", \"dropoff_borough\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "mN7iqAtjNydN"
   },
   "outputs": [],
   "source": [
    "#Droping the no needed any longer column\n",
    "avg_wait_time_per_taxi_per_borough = avg_wait_time_per_taxi_per_borough.drop(\"next_pickup_timestamp\", \"waiting_time\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PZqzNxxEN-Qw",
    "outputId": "dcd5a8ea-efc6-418c-d108-e00530d99538"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+------------------------+\n",
      "|        hack_license|dropoff_borough|avg_waiting_time_seconds|\n",
      "+--------------------+---------------+------------------------+\n",
      "|001C8AAB90AEE49F3...|       Brooklyn|                  5940.0|\n",
      "|001C8AAB90AEE49F3...|      Manhattan|                  3510.0|\n",
      "|0025133AD810DBE80...|      Manhattan|                  2400.0|\n",
      "|002C093A2CB9FD40C...|       Brooklyn|                   450.0|\n",
      "|002C093A2CB9FD40C...|      Manhattan|      1029.2307692307693|\n",
      "|002C093A2CB9FD40C...|         Queens|                  1020.0|\n",
      "|00374328FBA75FBFC...|         Queens|                    null|\n",
      "|00447A6197DBB329F...|       Brooklyn|                  2940.0|\n",
      "|00447A6197DBB329F...|      Manhattan|                  2850.0|\n",
      "|00447A6197DBB329F...|         Queens|                  4800.0|\n",
      "|0046F1E91AA13DEDE...|      Manhattan|       553.3333333333334|\n",
      "|00567B1CBFD51DDFA...|      Manhattan|                   504.0|\n",
      "|0057CCB5BA8D29E34...|      Manhattan|                    null|\n",
      "|006114F940CB87B3A...|      Manhattan|                   555.0|\n",
      "|006114F940CB87B3A...|         Queens|                  4620.0|\n",
      "|006313464EC98A24B...|      Manhattan|                  1575.0|\n",
      "|006B6BD90C7B5C985...|      Manhattan|       686.6666666666666|\n",
      "|00711D0CC3FB5BC90...|       Brooklyn|                 45060.0|\n",
      "|00711D0CC3FB5BC90...|      Manhattan|                  1650.0|\n",
      "|00711D0CC3FB5BC90...|         Queens|                  2700.0|\n",
      "+--------------------+---------------+------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show the results\n",
    "avg_wait_time_per_taxi_per_borough.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZBNuVbb2OFJY"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "## Computing the number of trips that started and ended within the same borough##\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "As80QGodOEj3",
    "outputId": "6773e244-26d4-4e37-9c5f-d84b9a9e8e10"
   },
   "outputs": [],
   "source": [
    "same_borough_trips = df_final.filter(col(\"pickup_borough\") == col(\"dropoff_borough\"))\n",
    "\n",
    "# Count the number of these trips grouped by borough\n",
    "count_same_borough_trips = same_borough_trips.agg(count(\"*\").alias(\"number_of_trips\"))\n",
    "\n",
    "\n",
    "count_same_borough_trips.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jl2Q8msSOdbH"
   },
   "source": [
    "## The number of trips that started in one borough and ended in another one\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PB6KTLiKOb97",
    "outputId": "7811d432-267e-40a3-c433-c6e9eae83dd0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|number_of_trips|\n",
      "+---------------+\n",
      "|          11403|\n",
      "+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filter rows where pickup_borough is not equal to dropoff_borough\n",
    "inter_borough_trips = df_final.filter(col(\"pickup_borough\") != col(\"dropoff_borough\"))\n",
    "\n",
    "# Count the number of these trips grouped by pickup and dropoff boroughs\n",
    "count_inter_borough_trips = inter_borough_trips.agg(count(\"*\").alias(\"number_of_trips\"))\n",
    "\n",
    "count_inter_borough_trips.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "xwEywulFOi48"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
